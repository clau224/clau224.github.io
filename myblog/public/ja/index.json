






[{"content":" 1. 为什么我想聊聊这个？ # 在从Java转向Go后，有一个我比较迷惑的点，为什么我在编译时，会自动生成wire_gen文件和gen_provider文件，多了一道工序，它有什么用呢？\n因为，这与我之前Java使用的Spring容器似乎不太一样，Spring容器是动过类加载的方式，加载并通过反射来实例化出各个bean的，所有的依赖都是自动注入，非常方便。而Go的Wire框架，看起来要先通过像是静态编译的方式，通过go generate来收集组件都依赖了哪些其他组件，然后再对各组件进行实例化。\n当然，这些都是我的推测，Wire框架它对我是一个黑盒。这导致我在使用Wire框架时不够熟练，比如我要删除一个组件，那么我应该更改哪些配置文件，应该重新执行哪些指令，来自动生成哪些文件。那么这篇blog，我就是想从底层原理出发，对Wire框架产生一个详细的认知。毕竟“工欲善其事，必先利其器”嘛！\n那么，让我们开始吧。\n2. Wire框架是否能类比成Spring框架？ # 在一开始，我想确认Wire框架究竟是做什么用的。我比较熟悉Spring框架，同时按照我当下浅薄的认知，我觉得他们的定位相似。那么我们就类比两者，来一步步了解Wire框架。\n那么，我想从「配置方式」、「注入时机」、「依赖检查」、「运行时容器」四个方面分别了解。\n2.1 配置方式 # 对于Java，通过@Bean、@Component系列注解，来声明Spring Bean；同时，在使用到这些Bean的地方，通过@Autowire、@Resource等注解就可以完成注入。 而对于Go，则需要指定以下配置：\nProvider：它是定义 “如何创建对象” 的函数，每个 Provider 函数负责实例化一个具体对象。若该对象依赖其他对象，直接在函数参数中声明依赖。 Injector：定义需要组装哪些对象。形象一点说，Provider告诉你做一道菜需要哪些食材，而Injector则是你真正要点的菜的清单。你会按需点菜。 wire_gen：它是Wire框架自动生成的，它能帮助我们自动生成「调用Provider」的实现。用上面的例子，相当于根据你的订单还有菜品做法，自动生成一套做饭指令，等待执行。 至此，Wire框架配置已完成。 2.2 注入时机 # 对于Java，在服务启动时，会扫描并加载Spring Bean。当该Bean实例化完成后，会被注入到Spring容器中。如果在实例化的时候，涉及到其他依赖的Bean，那么会从容器中取出该成员Bean（或者执行成员Bean的实例化），并根据对成员Bean的依赖，将其注入到当前Bean中。整体是在服务启动时完成。\n而对于Wire框架，则并不是这样的，根本原因是Wire它并不是一个容器，它本质上是一个编译时依赖注入工具。\n为什么这么说，因为Wire的注入逻辑，在服务启动之前就已经确定，我们通过代码生成的方式生成wire_gen；然后，在编译阶段，相关逻辑就会嵌入可执行文件中了。 在运行阶段，直接调用可执行文件中的注入器函数，获取已组装好的对象。 而这也是Go启动为什么那么快的原因。没有反射，纯函数调用！ 2.3 依赖检查 # 因为注入时机的不同，Spring框架和Wire框架的依赖检查的时机也完全不同。\n对于Java，它会在解析@Autowired等注入注解时，去尝试分析Bean之间的依赖关系，检查所依赖的Bean是否能初始化或者已经注入到了Spring容器中。如果存在依赖缺失，会出现 NoSuchBeanDefinitionException 类似的异常信息；而如果出现了循环依赖，且无法解决，则会出现 BeanCurrentlyInCreationException 类似的异常信息。相关的依赖问题，不会在编译器出现。\n而对于Wire框架，依赖的检查是在编译前，也就是wire_gen在生成时，会进行校验。在生成wire_gen的时候，会静态分析所有Provider的依赖关系，尝试构建依赖链。如果存在依赖缺失，则Wire直接报错并返回缺失提醒；如果出现了循环依赖，会直接报错并提示循环依赖。\n2.4 运行时容器 # 对于Java，它持有了一个运行时容器BeanFactory，所有的Bean都往里面注入，随用随取，BeanFactory管理了所有Spring Bean的生命周期。整体采用单例的设计模式。\n但对于Wire容器，分析完上面三点后，我有个大大的问题，Wire框架中某组件被多次注入到不同组件的时候，每次都是通过Provider创建出一个新对象么？\n然后我调研了一下Wire框架，它没有任何容器的概念，或者说，Wire框架只是作用于编译阶段，到运行阶段后它就“消失”了。那么，回到上面的问题，在编译阶段，每次注入某组件时，都会调用Provider方法。换句话说，如果不做特殊处理，那么Wire注入的组件是多例。\n官方对此也有说明：\n(Reference guide.md)\nProviders are just functions. They can be simple constructors, or they can have side effects, or they can return singletons. Wire doesn\u0026rsquo;t care; it just calls the functions as needed.\n3 Wire框架的设计理念的优劣势 # 我觉得整理一下Wire框架的优劣势，这对我未来做技术选型是有帮助的。\n我认为Wire框架在以下方面是有优势的：\n最重要的是依赖关系清晰，Spring容器相对黑盒，提供便捷性的同时，逻辑比较复杂；而Wire比较简单粗暴，依赖出现问题直接断点调试。 性能好，wire是通过代码生成实现的依赖注入，没有Spring容器的反射、动态代理、Bean池管理等运行时开销。 编译时就进行依赖检查，能提前暴露问题。 但我认为也有劣势：\n多了wire_gen生成这一步，每次增加组件后，都需要执行这一步，有一丢丢繁琐。 需要手动管理单例，如果能像Spring容器，通过一个@Scope自动管理就好了。 灵活性比较差，因为依赖关系都是固定死的，有时需要根据环境进行动态注册，Wire是支持不了的，而Spring可以通过@Conditional来实现。 到这为止，我可以给Wire框架下一个定义了： Wire就是一个DI框架，只负责依赖识别以及做依赖注入代码的生成，像Spring的IOC、AOP这些能力是不支持的。\n4. provider_gen.go是做啥的？ # 我在团队项目下，发现provider_gen.go文件，看名字并不是手写。它是怎么生成的？为了解决什么问题？\n首先，它并不是wire框架生成的，而是利用go generate工具链生成的。这实际上是Go一个最佳实践，针对项目中大量重复且功能一致的对象，可以通过模版的方式批量创建。比如，针对DAO层的对象，其模版可以是——\n// 模板：dao_provider.tpl package dao import \u0026#34;your/project/db\u0026#34; // New{{.Name}}DAO 初始化 {{.Name}}DAO func New{{.Name}}DAO(db *db.DB) *{{.Name}}DAO { return \u0026amp;{{.Name}}DAO{ db: db, // 固定依赖数据库连接 } } 其实就是一个简化操作的作用。当我们创建好了模版，并指定了使用该模版的对象，使用go generate就能一键生成Provider方法，这些方法的实现会被放置到provider_gen.go中。\n5. di.go是做啥的？ # 同样的，在团队项目下，也发现了di.go文件，它是怎么生成的呢？ 我们在Go项目中往往会定义一个InitializeXXX的注入函数，并使用 wire.Build 函数指定需要组合的 Provider。当我们执行Wire工具，就会自动生成di.go，具体流程是这样的：\n解析 wire.Build 中指定的所有 Provider 方法 构建依赖关系图（分析每个 Provider 的参数依赖） 生成一个完整的初始化函数，替代手动定义的 InitializeApp 将生成的代码写入 di.go 文件 这里，InitializeXXX往往会变大很多，因为它会增加底层的依赖的provider调用。 ","date":"2025-08-30","externalUrl":null,"permalink":"/posts/go-wire%E6%A1%86%E6%9E%B6%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86%E6%8E%A2%E5%AF%BB/","section":"Posts","summary":"在我从Java转向Go后，一直迷惑于Wire框架的作用，看起来它和Spring框架功能相似，它是怎么work起来的呢？","title":"Golang Wire框架 底层原理探寻","type":"posts"},{"content":"","date":"2025-08-30","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":" 1. 为什么我想聊聊这个？ # 掰指头算算，北漂回连加入L团队已经快两个月了。这两个月中的每一天，都有陌生知识\u0026quot;撞入\u0026quot;我的脑袋里。我似乎始终处于懵懂的状态，说实话，这有点不专业，像一个初入职场的小白一样，每天等待着被动发现新的领域。\n也说来惭愧，关于「加入新团队后，最应该关注哪些点？」，我似乎从来没有想过这个问题。19年我以校招生身份加入M团队后，团队对我的成长给予了极大的宽容；而后在合作团队Leader的“勾搭”下，加入了X团队，业务领域、技术栈、做事方法论都是相似的，似乎每一段工作经历的开始，都很幸运得有惊无险地度过。 回大连加入L团队后，我表现出了极大的不适应。一方面，用惯了傻瓜式的封装平台，再转向较原生的技术栈/攻击，让我无所适从，自由但繁杂的配置，让我在推进研发流程时不断遇到阻塞。另一方面，业务方向与我过往经历相比，是一片陌生的领域，这让我在做决策时畏手畏脚，或者会出现想当然的盲目自信。\n上面都是客观原因，主观原因还是菜，菜是原罪。我的适应能力也比较差，从上学开始，每次进入新的学科/领域，都比别人反应慢半拍。但我也有我的个人优势，当我熟悉了环境，熟悉了规则，那么我将比很多人都表现的要好。结合我的个人特点，我能否进行刻意练习？\n这是我写本篇blog的根本原因。我将挑选出几个关注点，将我有限的精力投入其中，快速攻克，它们将覆盖80%以上的研发场景。至于其他的，就随着日常工作慢慢了解吧。\n来，让我们开始吧！\n2. 从工具角度，优先跑通哪些研发流程？ # 2.1 本地开发流程 # IDE及插件：非常关键，像idea、vscode等，可以共享团队服务启动/debug配置，能省很多配置精力。 研发辅助工具：要与团队确认，比如使用了哪些中间件连接工具，最好的方式就是看同事安装了啥。 其余的Git/brew等常用工具就不说了，看个人习惯。 2.2 代码协作流程 # 代码分支模型：确认是否按照主分支、集成分支、开发分支划分，以及它们的合并时机。 提交规范：Comment是否有格式要求。部分团队会基于固定格式进行解析作项目管理。 2.3 代码审查流程 # 代码工具：代码平台是哪个，gitlab/github/搭建内部平台。 审核流程：提MR是在什么环节节点提出，MR审核周期是多少。 审核规范：是否有约定俗称的checklist。如何定义好的审核。是否有千行评论等团队要求。 审核人：MR必须经过哪些角色审批。 2.4 测试流程 # 环节确认：确认发版上线钱，都需要走哪些测试流程。 测试工具：单元测试工具、压力测试平台、接口测试平台、Diff测试平台等等。 阈值确认：确认各环节测试必须达到多少阈值才能通过。 2.5 CI/CD与发布流程 # 持续集成：查看 Jenkins/GitLab CI 配置文件，如.gitlab-ci.yml，了解代码提交后自动运行的测试和构建步骤。 镜像部署：镜像平台是哪个，不同环境的镜像仓库分别是哪个。 环境确认：确认有哪些环境，例如test、beta、staging、prod-clone、prod 测试部署：如何部署test/beta/staging等测试环境。 生产部署：发布审批流是怎样的，回滚方案是怎样的，是否有稳定版镜像直接回滚？ 2.6 稳定性保障流程 # 监控日志：监控平台是哪个；日志平台是哪个，查找日志时，过滤条件如何设置。 故障演练：故障演练平台是哪个；演练周期是怎样的；会进行哪些场景的演练。 2.7 项目管理流程 # 迭代周期：迭代周期是多少，迭代进展会是什么时候；需求评审会是什么时候；周会是什么时候；还有其他什么会。 工作项管理：需求-任务怎么分层；有哪些关键字段会影响团队协作；哪些关键字段影响团队考核。 3. 从服务角度，优先摸透哪些关键实现？ # 3.1 服务整体架构 # 按照过往经验，一般按照五视图法就能宏观了解整个系统。五视图分别是指逻辑架构、开发架构、运行架构、物理架构和数据架构。 如果团队没有全部视图，至少应该和团队成员讨论下运行架构，也就是服务的上下游调用关系，除了常规的Http/rpc调用，还会涉及MQ事件、定时任务。\n3.2 启动与初始化流程 # 它是服务能否正常运行的基础，服务起不来什么事情都做不了。可以关注以下细节：\n启动类入口：确认服务启动类，确认启动类的扫描路径等等。\n启动依赖：必须成功连接的外部服务，如 MySQL、Redis、Kafka，甚至有时会检查外部服务是否启动。\n启动参数：启动参数有哪些，作用分别是什么，哪些参数是必填的。\n3.3 Top1关键业务链路 # 这里不贪多，只需要确定当前服务关键Top1的接口是什么。了解Top1业务链路，能让让我们了解这个服务是做什么的，可以通过以下信息对整体业务有一个大概认知：\n明确参数意义：每个参数，都可能牵扯出一些业务逻辑。不需要深挖每个参数是怎么处理的，只需要明白参数背后的业务含义是什么。\n明确流程步骤：可以画一个流程图，最简单的链式就行。让我们对整体流程有一个大概了解。涉及的组件名称也要记录下来，方便跳转。可能要重点关注下一些if-else逻辑，比如编码在代码中的业务规则。\n明确外部交互：调用了哪些外部服务，使用了哪些外部中间件，都记下来。\n3.4 配置系统 # 配置错误是新人最易踩的坑（如环境错配、参数填错导致功能异常），需掌握配置从哪来、怎么生效、如何改。重点关注以下细节：\n配置加载来源与优先级：配置可能来源于本地配置文件（resource下yml、config下配置文件等等），外部配置中心（比如Apollo、Nacos等），甚至在某些其他仓库（比如Ceylon仓库等）。它们的优先级是怎样的，加载顺序会决定覆盖性。\n核心配置项：依次确认这些信息，端口、环境标识、日志级别。\n中间件配置项：先确认用了哪些中间件，然后定位到它们的配置在哪里。\n配置刷新机制：是热部署，还是需要重启服务。\n3.5 数据交互 # 数据层交互：都用了哪些存储引擎，表都有哪些，它们都是做什么用的？\n缓存策略：是否使用了缓存，用了哪些缓存，key是怎么生成的，过期时间是怎样的。\n外部系统交互：都依赖了哪些外部服务，是怎么交互的（http、rpc、mq）；超时机制和重试机制；调用外部服务是为了获取什么信息？\n3.6 异常机制 # 异常处理流程：是否有全局异常处理器，像java里的@RestControllerAdvice类，明确哪些异常会被捕获并转化为特定响应；以及未捕获的异常，会发生什么，是否打印异常栈，是否返回默认错误页？\n熔断与降级：当外部服务不可用时，接口是否会熔断，触发熔断的配置是多少？当前服务负载过高时，是否有功能降级；核心功能是否有数量降级，比如控制返回数量。\n3.7 监控/日志埋点 # 监控平台：各个环境的监控平台地址，尤其是线上环境，各个服务做成书签，方便随时监控。\n监控指标埋点：监控了哪些关键指标；当异常发生时，特定类型的异常应该看哪些指标；特定指标出现异常能反馈出什么问题。\n日志平台：各个环境的日志平台地址，尤其是线上平台。日志平台该怎么用，使用哪些关键字来做过滤。\n日志规范：有没有统一的日志记录工具；日志框架都能打印哪些参数；核心的日志输出点有哪些，比如代码出现问题，需要优先查看哪些日志；日志的使用级别有哪些。\n运维脚本：常用的比如tail -f agg.log等。\n4. 从业务角度，优先关注哪些产品细节？ # 4.1 核心业务流程 # 用户视角的高频主流程：比如浏览商品-\u0026gt;加购-\u0026gt;下单-\u0026gt;支付-\u0026gt;收货-\u0026gt;售后全流程。可能服务只是这个环节的一小部分，但宏观链路至少简单了解一下。\n异常业务流程 # 用户视角的异常流程：比如库存不足时会怎样，支付超时后会怎样，秒杀没抢到会怎样。\n4.2 核心业务指标 # 交易类指标：电商金融使用的多，比如GMV（成交总额）、转化率（下单率 / 支付率）、客单价、复购率等等。对我们研发有什么用呢：\n优化结算流程的响应速度（如支付接口耗时 \u0026lt; 200ms），减少用户流失； 通过缓存策略提升大促期间商品详情页加载速度，间接提升转化率； 监控交易链路的失败率（如支付失败率 \u0026lt; 0.1%），避免直接损失。 用户类指标：DAU（日活）、MAU（月活）、用户留存率（7 日留存）、人均使用时长等等。对我们研发有什么用呢：\n优化客户端启动速度（如冷启动 \u0026lt; 1.5 秒），提升用户体验以增加使用时长； 监控服务端接口错误率（如 5xx 错误率 \u0026lt; 0.5%），避免因服务异常导致用户流失； 通过技术手段支持 A/B 测试（如动态配置发布），快速验证功能对留存的影响。 4.3 核心体验指标 # 性能指标：接口平均响应时间、99% 耗时（P99）、吞吐量（QPS）\n稳定性指标：服务可用性SLA、故障率、故障恢复时间MTTR\n4.4 成本指标 # 我把指标放到了业务角度中，因为人力资源、机器资源会影响业务布局。如果我们是中小型企业或者创业团队，那么它是我们在做产品时需要格外关注的点。\n我认为关键的成本是人力成本、流量成本（买广告这些）、机器成本，不过这里先不展开讨论。\n","date":"2025-08-28","externalUrl":null,"permalink":"/posts/%E5%8A%A0%E5%85%A5%E6%96%B0%E5%9B%A2%E9%98%9F%E5%90%8E%E6%88%91%E4%BB%AC%E6%9C%80%E5%BA%94%E8%AF%A5%E5%85%B3%E6%B3%A8%E5%93%AA%E4%BA%9B%E7%82%B9/","section":"Posts","summary":"加入新团队后，陌生的技术栈和工具是否影响日常研发效率呢？我正在经历这种苦恼。我在想，能否梳理一套核心的待确认点，专业且高效地一步问到位\u0026hellip;","title":"加入新团队后，我们最应该关注哪些点？","type":"posts"},{"content":" 为什么我想聊聊这个？ # 在加入L团队后，我负责了一个多路召回的技术设计，在其中，我主要对Milvus做了技术选型和评估，但部分过程与结论不被团队所认可。\n我认为核心因素有两个，一是我对业务领域（含上下游链路）的理解不到位，二是有一些团队标准/导向是我未预料到的。\n入职一个多月以来，我观察到了与之前M团队间的一些差异点，这让我感到新鲜，但也有稍许不适应，简单说说：\n性能分析精细度：\nM团队侧重于功能性验证，对于性能分析，其隶属于技术设计的可行性分析部分，采用三步法：评估未来3年数据增长 + 测出最大QPS/性能拐点 + 制定指标红线（约定红线SOP）。 L团队有POC阶段，该阶段专门用于中间件的功能性验证和性能验证。在性能验证上较为细致，会严格使用真实数据量+真实数据分布。各类参数都要进行实验组覆盖，确认自变量对整体性能的影响及趋势。 成本控制：\nM团队在设计阶段，会粗估服务器数量；最终服务器数量的确认，会在测试阶段的性能压测期间进行评估调整。对于服务器数量，一般重点考虑突发情况，只估上限不估下限。同时底层有中间件团队负责快速扩容+技术支持。 而L团队则倾向于极致的成本管理，包括机器型号、所在机房等底层因素都需要纳入考虑。对成本把控较严格，较低的资源使用率会被挑战。 方案倾向性：\nM团队虽然是非业务团队（平台工具），但比较业务导向，更关注需求的合理性、业务对架构的影响。做性能方案选择时，在性能差异不大（一般5%内）的情况下，会倾向于易扩展、易维护、易排查的方案。 L团队在做性能分析时，会选择性能最极致的方案；且对延迟较为敏感，评判标准会精细到0.1ms级别。此外，L团队与国外团队存在协作交互，方案会充分参考各方意见。 发现有些事儿没系统思考过。从毕业后开始工作，其实一直身处在较熟悉的环境中，团队流程/标准/导向较为相对固化，很多做法遵循群体潜意识就会得到解决。加入L团队后，诸多问题同时暴露出来，加上本人对新环境的适应能力一般，多少有点难绷。\n因此有了本篇blog。我想在这里，搞定一件事情——\n所谓南橘北枳，从M团队到L团队，一味延续习惯会出现问题。是否可以梳理出一套方法论，无论在哪个团队，都能高标准完成中间件技术选型？\n不同业务场景，是否需要差异化评估？ # 首先，我认为，有差异也有共性。核心都是三要素：业务、技术、成本。\n一套方法论不可能生搬硬套到所有团队，不同业务场景对于中间件评估的侧重点会有些许不同；同时，一个团队的业务场景，可能同时包含多种业务特性。\n0. 必需的基本调研 # 功能性匹配：中间件是否支持业务核心需求。 基本可靠性：无单点故障风险、数据不丢失的基础保障能力。 兼容性：与现有技术栈（语言、框架）的集成可行性。 1. B端业务 # 企业级应用，业务逻辑复杂。\n复杂场景适配：是否支持业务逻辑中的特殊需求（如复杂数据结构等）。 可扩展性：B端业务经常发生功能扩展/变更。对于一些可以预见的产品诉求，中间件是否有能力支持。 运维可控性：B端逻辑复杂，是否提供精细化监控/日志（如业务链路追踪），便于问题定位。 2. C端业务 # 面向用户，并发流量较大。\n高性能与吞吐量：C端流量远大于B端，中间件的并发处理能力，能否支撑峰值流量。 低延迟：数据读写 / 消息传递的延迟指标，是否影响用户体验（如 Redis 的响应时间、MQ 的投递延迟）。 弹性伸缩：在流量波动时，能否快速扩缩容（如 Redis 集群分片、MQ 的动态队列扩容）。 快速故障恢复：C 端业务一旦出现故障，影响范围广、用户感知强。那么是否具备快速故障恢复机制呢？ 3. 创业团队 # 资源有限，快速迭代。\n资源占用：要考虑CPU、内存 等资源消耗是否较低，租用太多服务器成本会难以接受。 轻量级部署：是否支持快速搭建（如单节点部署、容器化一键启动），降低初期运维成本。 学习与使用成本：API 是否简洁、是否易于开发者快速上手，减少团队学习投入。 4. 金融政务 # 强合规，高安全。 没做过类似方向，但结合公开的技术分享，我简单梳理出以下几点：\n高可靠性与灾备：是否支持多副本、异地容灾（像Redis的主从+哨兵、MQ的多集群同步这种），确保服务不中断。 数据安全性：传输/存储是否支持数据加密、访问权限严格控制。 合规审计：能否记录完整链路的操作日志，满足监管审计要求。 仅停留在宏观视角做分析，往往难以覆盖全部细节。为确保中间件评估的全面性与可操作性，我将进一步拆解每个评估维度，细化为可落地的实施要点，形成相对标准化的 checklist。\n评估中间件时，有哪些核心纬度？ # 我梳理出八个纬度，纬度较多，但并不是在每个需求中都要同时考虑。\n纬度的列举以及纬度内的实施点，都是参考借鉴他人的优秀设计并结合本人过往工作经验总结而来，会有疏漏，欢迎补充！\n1. 功能性维度 # 你引入某中间件，肯定希望通过它解决某些业务/技术难点。但它是否真的能解决问题呢？需要验证。\n核心能力覆盖：\n【难点梳理】列出必须要解决的具体业务难点，确认目标很重要，避免疏漏和跑偏\u0026hellip;\n【能力拆解】针对每个难点，拆解为中间件的具体能力需求。这里先只提需求，不要收到具体中间件的能力的影响。\n【基础功能验证】写一个dmo，它会帮我们暴露很多问题。\n确认数据的适配性，中间件能否完美适配业务数据；如果不能，业务数据能否类型转换后接入中间件。 确认功能特性的正确性： 确定测试数据，使用具备区分度的测试数据进行验证。例如测试存储型中间件时，涉及到query功能验证，那么需要准备好重复率较低的数据集以及对应的Query。 生成验证demo，接入中间件client后可以采用单测+断言进行快速验证。初步判定可行后，再封装中间件Client以复用于开发阶段。 执行链路后结果符合预期，且执行期间无异常/报错。 确认结果的完整性，部分中间件协议不识别某些数据类型，可能出现部分数据丢失的情况。 【异常功能验证】模拟异常情况，尤其是上游链路传递的可能的异常情况。\n非法数据处理：传null、类型不匹配会怎样？这决定了校验器的实现。 连接中断恢复：少部分场景需要模拟网络断开的故障，以判定中间件是否符合功能需要，比如DB大事务场景。这也决定了重试、事务等机制的实现。 【边界情况验证】测试功能临界值\n不清楚中间件哪些资源存在边界情况，可以咨询LLM。\n边界数据处理：信息size过大等非常规场景，边界上限是多少，需要如何处理？ 资源耗尽测试：部分场景，业务数据正常使用中间件时，某些资源存在瓶颈，比如连接资源超限、线程资源耗尽等情况。这可能影响功能的正确性。 深度功能覆盖：在确认能实现业务功能后，它是否真的能上线，还取决于多种因素：\n【灰度策略验证】开发到上线之间的多实验版本控制、蓝绿发布等环节，都可能出现中间件无法胜任的情况，需要重点考虑。\n如果是存储类型中间件，如何保存多个版本的数据？放一张表，还是设计实验版本表？ 放一张表，该表是否过宽？是否支持动态增加字段？表内字段是否有上限？ 设计实验版本表，如何平滑切换？如何做数据同步（增量+存量）？ 如果是通信类型中间件，如果保证链路隔离？ 比如，如何保证链路标识会一直存在？Java里的ThreadLocal等机制是否会导致标识丢失。 如果链路存在nginx等反向代理，如何保证流量分发给预期的下游服务器？ 如果是任务调度类型中间件，如何保证各实验链路执行的准确性？ 还涉及到业务实现，各实验链路都需要接受调度吗？所以采用广播模式还是单点模式？ 【配置灵活性确认】部分场景需要动态配置与能够自定义策略\n确认参数能否动态调整：例如动态线程池、动态缓存过期策略、动态MQ消费线程数。\n如果可以动态调整中间件核心参数，那么在故障发生时，就多了一种快速消除故障的手段，比如线程池打满、MQ消费能力不足的场景。\n【功能扩展性确认】部分业务场景极其复杂，且随着业务演进只会更复杂，中间件能否撑得起来？\n是否支持API 扩展与二次开发支持？比如任务调度中间件开放任务触发规则 API，可实现根据业务数据动态生成调度策略；缓存中间件支持自定义缓存淘汰算法接口。 中间件是否支持通过插件扩展核心功能？这是API网关类型中间件非常值得关注的点。 2. 性能维度 # 首先列举一下高频出现的性能指标：\n关注指标 指标解释 吞吐量指标 单位时间内处理的请求数（QPS） 或 数据量（MB/S） 响应效率指标 延迟（AVG、P99、P90等），长尾延迟发生率（如超过1s的请求占比） 系统资源指标 在达到目标性能时，CPU、内存、磁盘IO、网络等硬件资源的占用率 稳定性指标 请求成功率、失败率、超时率，服务可用性 资源池指标 线程/协程活跃数，连接池线程活跃数，队列堆积数 其实，指标大盘很容易搭建（毕竟也可以服务之间互相参考），真正要在性能测试中投入人力设计的是对照实验。\n在对照实验中，又以自变量、因变量、控制变量最为重要。那么，我们应该考虑哪些因素作为我们实验变量呢？\n自变量的考虑要素\n硬件资源：核心关注 CPU（需明确型号及核心 / 线程数）、内存（容量及频率）；部分中间件（如消息队列、缓存）需额外考量磁盘 I/O 性能（读写速率、IOPS）及存储介质（HDD/SSD）。 中间件版本：不同版本的中间件在性能优化、功能支持上存在差异。 请求并发度：以虚拟用户数（VUS）为核心指标，需匹配实际业务场景的并发量级。 处理并发度：重点关注连接池（如数据库连接池、HTTP 连接池）、线程池的核心参数（核心线程数、最大线程数、队列容量）；同时需纳入批处理 size（如数据批量读写大小）的影响。 压力模型：阶梯加压（最常用，测试性能拐点）/ 峰值持续 / 脉冲加压。 存储类中间件： 字段类型：直接影响检索效率（如数值型 vs 字符串型查询耗时差异）。 索引结构：需覆盖单字段索引、联合索引（含索引顺序），明确索引对查询的加速 / 冗余影响。 表结构：包含分表策略（垂直分表 / 水平分表）、存储引擎选型（如 InnoDB/MyISAM）、页大小等关键参数。 数据量：需划分不同数据量级（如 10 万级、100 万级），测试数据量增长对性能的衰减趋势。 查询方式：区分等值查询、范围查询、模糊查询等，明确不同方式的性能差异。 查询条件：影响索引命中与否及数据扫描范围。 条件复杂度：设置单条件查询（如仅基于主键查询）、多条件并列查询（AND 连接）等不同复杂度场景。 返回字段影响：设计完全覆盖索引查询、部分覆盖索引查询，验证返回字段对查询效率的影响程度；设计不同数量返回字段数，确定数据库IO对性能的影响。 数据过滤范围：通过调整查询条件的数据过滤比例，如查询 1%、10%、50% 的数据量，观察数据范围扩大时查询性能的衰减趋势，定位性能瓶颈。 函数使用场景：加入在查询条件中使用聚合函数（如 SUM、COUNT）、字符串函数（如 SUBSTRING）等情况，评估函数计算开销对查询性能的影响，确定是否导致索引无法使用。 通信类中间件： todo 因变量的考虑要素\n因变量，就是上文提到的吞吐量、响应效率、系统资源、稳定性、资源池等指标，但需要和自变量建立映射关系，例如可以通过折线图等方式，直观展示因变量与自变量间的某种关系。\n可视化方案：\n折线图：\ntodo：各场景最佳展示方案。\n趋势解读 关于趋势，一般有以下几种：\n单调性：因变量会随自变量增加，而持续上升、下降或者波动。例如，并发数增加时，延迟持续上升，因为存在资源竞争。 饱和点：因变量不再随自变量变化的临界点甚至是拐点。例如，并发数 \u0026gt; 1500 时，吞吐量稳定在 2500TPS，说明服务端处理能力达上限。再次提升并发数，吞吐量可能会下降，说明服务端趋于崩溃。 异常波动：趋势中突然出现的非预期变化。例如，延迟在VUS = 300 时突然跳跃，说明可能触发了数据库连接池耗尽。 控制变量的考虑要素\n非自变量外的其他变量，都需要控制保持一致。 3. 可靠性维度 # 故障容错：中间件出现故障不可避免，是否能自动恢复或降级。 单点故障处理： 是否有多节点冗余，是否支持自动选举新节点接管故障节点？ 故障检测机制：如何判断该中间件服务down掉了，或者处于一个错误的状态？ 服务器故障处理： 服务器宕机：进程重启后，是否能通过日志/checkpoint 快速恢复状态？数据是否会造成丢失？ CPU/内存资源过载时，是否有保护机制（如拒绝策略、降级非核心功能等）？ 故障灾备能力： 是否支持数据备份？备份频率？ 是否有灾备演练与预案？ 可用性：能反应长期运行的稳定程度。 该中间件SLA是多少？平均无故障时间和平均恢复时间是多少？ 是否有成功应用于大规模生产环境的先前案例？ 长期运行可能存在版本升级，是否支持平滑升级？ 数据一致性：在分布式场景或异常中断时，数据是否会丢失、错乱（如是否支持事务、数据同步策略）。 支持怎样的级别，强一致性还是最终一致性？ 是否支持事务？事务如果超时是怎么处理的？ 出现了网络中断，恢复后该中间件会怎么处理？ 4. 成本维度 # 直接成本：部署所需的硬件 / 云资源费用、商业授权费用。\n硬件/云服务器成本\n服务器配置+服务器数量：在估算配置时，要考虑单节点需要的CPU、内存还有网络带宽。 资源利用率：考虑CPU/内存等利用率是否在合理区间？过低会产生资源浪费，过高可能会导致服务出现不可用隐患。目前所在的L团队，CPU使用率控制在不超过60%。在此条件下尽可能保持较少的Pod数量。 存储成本：数据持久化是否支持分层存储（冷热数据分离）；备份数据存储周期，以及单位容量的价格。 软件订阅付费成本\n确认软件的收费模式：如果是商业版本，可能会按照节点数/核心数/吞吐量计费；还有可能采用SaaS订阅模式，会按照调用量或者租户来收费。 附加服务成本：技术支持、升级维护是否收费？这就不得不提Jfrog了，在X团队时被坑的很惨，以色列人还是会赚钱的。 网络与流量成本\n跨机房/跨地域数据交互的流量费用。这个也是我在加入L团队后，才发现AWS跨机房是收费的。 部分中间件（如API网关）可能采用流量计费或请求计费模式。 间接成本：学习成本（团队培训）、运维成本（人力投入）、迁移成本（替换旧系统的代价）。\n不要小看这个成本，在资源有限的团队，人力成本是开支大头。在间接成本较高的情况下，如果踩坑了，会让资源有限的团队进入万劫不复的境地。 5. 扩展性维度 # 规模扩展：随着业务发展，数据量/并发度会越来越高，能通过增加节点数量提升可用性\u0026amp;性能，很关键。\n集群部署能力：是否多节点；要避免伪集群。 分片机制：分片策略是怎样的；是否支持自动重分片；分片容量/分片数是否有上限。 集群一致性保障：各节点间的数据同步机制；多节点场景下的脑裂问题。 数据量扩展：通常和上面的分片挂钩，需要考虑该中间件的单机/集群容量上限。以及是否支持数据归档、清理。 扩展自动化：是否支持自动扩缩容？扩缩绒触发条件是否支持配置等等。 功能扩展：\n插件化能力：是否支持不重启中间件即可启用/禁用插件功能？是否可以自定义插件？ 接口扩展：是否开放核心能力 API？新版本是否兼容旧版本接口？ 业务定制化支持：是否支持自定义数据Schema？是否支持自定义规则/路由？ 6. 兼容性维度 # 技术栈适配：\n是否支持你团队的语言、框架、数据库等现有技术栈，可以先写一个demo跑通。 API 兼容性，协议是否支持。一般都提供client，或者提供http/rpc方式调用，确认即可。 环境适配：\n是否兼容不同操作系统，例如Linux系统版本等；以及芯片的兼容性，x86、ARM架构等。 版本兼容：\n在升级中间件版本时，要重点考虑此要素！不同版本间的是否能平滑升级。\nAPI 兼容性：新版本是否保留旧版本 API 接口；或者是否提供兼容层；废弃接口是否有过渡期等等。 数据格式：存储格式升级是否兼容旧版本；数据怎么迁移，有迁移工具？ 配置兼容：配置项是否有新增、删除或重命名，旧版本配置项是否暂时先兼容？不兼容，怎么迁移？ 依赖库：升级后依赖库版本是否变化，是否会对现有项目的依赖树产生影响？有幸升版过一次，这类问题非常隐蔽。 7. 安全性维度 # 一般考虑比较少，且会有专门的安全团队负责，先跳过。\n8. 生态与易用性维度 # 它重要又不太重要，毕竟我们做技术选型时，一般不会挑小众中间件。常见的技术架构中，使用的中间件都是高频出现的，我们一般不会是第一个趟坑的人。关于生态和易用性，这里我咨询了下LLM，整理出我认为比较重要的六点，也给自己未来的设计评估工作提个醒：\n开发成本：API 设计是否简洁、文档是否清晰，开发者上手难度（学习曲线）。 运维成本：部署、配置、监控是否便捷（如是否有可视化工具、自动化脚本）。 问题排查：是否提供完善的日志、监控指标，故障定位的难易程度。 社区支持：开源社区活跃度（贡献者数量、issue 响应速度、版本更新频率）。 商业支持：是否有厂商提供商业服务（如技术支持、培训），避免依赖单一社区。 生命周期：是否处于活跃维护阶段（无停产风险），未来演进方向是否清晰。 ","date":"2025-08-26","externalUrl":null,"permalink":"/posts/%E5%81%9A%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%E6%97%B6%E6%88%91%E4%BB%AC%E8%AF%A5%E5%A6%82%E4%BD%95%E8%AF%84%E4%BC%B0%E4%B8%AD%E9%97%B4%E4%BB%B6/","section":"Posts","summary":"在最近，我负责了一个多路召回的技术设计，主要对Milvus做了技术选型和评估，但部分过程与结论不被团队所认可。这也让我开始思考一个问题\u0026hellip;","title":"做技术选型时，我们该如何评估中间件？","type":"posts"},{"content":"在加入LineMan之后，我负责的是多路召回这部分。多路召回是干啥的呢？简单来说，当我们打开类似美团的外卖app，在无关键字检索的情况下，首页需要展示推荐餐厅。那么，都展示哪些餐厅呢，凭什么把它们展示出来呢？这就涉及到多路召回的逻辑了。\n同样的，本篇我依旧借助一些核心问题，来一步步加深我对多路召回的理解。如果能给各位带来新的启发，荣幸之至。\n[TOC]\n1、业务背景与召回系统价值 # 开始的开始，我依旧想从业务价值切入。尤其是在转向偏C端方向后，我更加认为技术是服务于业务的。\n那么，在外卖首页推荐场景中，关于业务价值我有三问：\n外卖首页推荐场景下，召回时的业务痛点有哪些？ 多路召回是怎么工作的？如何解决这些痛点的？ 解决了痛点，是否真的产生了价值呢？如何去评估？ 1.1、外卖首页推荐的业务痛点 # 如引言所述，几乎所有购物类APP都存在首页推荐。但是，在外卖场景中有一个比较鲜明的特殊性——决策周期短。\n相较于传统电商购物，用户在浏览外卖首页时，决策周期往往极短。想象一下，忙碌了一上午，中午饥肠辘辘打开外卖 APP，咱们肯定希望能在短短几分钟内就选定心仪的餐食下单，而不是花费大量时间筛选。\n外卖场景下，用户的需求多种多样。有的用户追求便捷性，希望能快速找到距离近、配送快的商家；有的用户看重性价比，对优惠力度大、价格实惠的商品更为关注；还有的用户执着于口味偏好，钟情于特定菜系或风味的美食。\n你所在的城市，外卖商家成千上万。面对如此海量的商家和商品信息，怎么快速且准确的猜中你的喜好呢？\n1.2、多路召回系统在其中的作用 # 关于上面的业务痛点，有一个稍专业些的词，叫“信息过载”。这正是多路召回系统能够解决的问题。它如同一个智能 “筛选器”，能够从平台庞大的商家与商品库中，依据不同维度的规则与算法，快速筛选出符合用户潜在需求的候选商家或餐品。\n比如拿1.1中的需求举例，多路召回能同时召回多个候选集合，它的每一路都对应不同的商业逻辑：\n可以根据用户当下所处的地理位置，快速筛选出周边可配送的优质商家； 可以分析用户过往点餐记录等行为，比较爱吃往往会一直爱吃下去； 甚至我们可以根据用户画像，找出口味相近的人群，看看他们都喜欢吃什么。 上面的召回逻辑很容易理解，非常符合我们的订餐偏好。那么，当我们的系统在引入多路召回后，怎么评判它是否真的产生了正向效果呢？\n1.3、外卖首页推荐的核心目标 # 首先声明一点，目前我所在的后端团队更偏向于底层，首要目标更倾向于服务稳定性保障，商业化目标更多的是算法团队来主导。\n尽管如此，我希望能看到背后的业务逻辑和价值。开发的代码赚更多的钱，或产生更大的用户粘性，是更有成就感的一件事。\n那么，观察业务效果是关键。关注了下业界核心的业务指标，有以下几种：\n相关性指标：我认为这类指标最关键。试想，召回的都是不相关餐厅，那么再怎么排序都没鸟用。 点击率（CTR）：召回候选集中被用户点击的比例（点击数 / 召回展示数）。若某路召回的 CTR 显著低于平均水平，说明该路径的相关性较差（如 “基于用户 30 天前行为的召回” 可能因需求变化而失效）。 加购率/下单率（CVR）：召回商品被加入购物车或最终下单的比例。相比 CTR，我认为CVR 更能反映召回商品的 “深层相关性”（比如用户点击后发现价格不符、距离太远，可能 CTR 高但 CVR 低）。 多样性指标：衡量召回的丰富度，避免同质化。毕竟把满满一页的川菜，赶在你上火的时候推给你，不太行不是？ 品类多样些：召回候选集中，不同品类的占比分布（比如前 5 大品类占比是否超过 80%）。可用 “信息熵” 量化：熵值越高，品类分布越均匀，多样性越好。 召回多样性：最终进入排序阶段的商品中，来自不同召回路径的比例（如 “基于历史行为”“热门推荐”“新品推荐” 等路径的贡献是否均衡）。若某一路径占比超过 90%，说明其他路径未发挥作用，多样性不足。 业务规则指标：多路召回需服务于平台的商业目标（如扶持新商家、提升高毛利商品转化等），毕竟还是要赚钱的呢！ 新商家召回率：平台新增商品 / 商家中，被多路召回策略命中的比例。若新商家长期无法被召回，可能导致平台生态僵化。 高价值商品召回占比：在召回候的选集中，高客单价、高毛利、高评分商品的占比。（过高过低都不好，高档餐厅不是人人能去的起） 以上，是我认为能较好衡量且易分析实现的商业指标。\n在分析完多路召回的业务价值后，来做下业界调研，看看多路召回系统在设计时需要考虑哪些核心原则。\n2、多路召回系统的核心设计原则 # 2.1、多样性原则 # 用户需求的多样性决定了多路召回系统必须具备丰富的召回维度。\n目前我负责的召回阶段，能力是单一的，只有通过ES进行召回（核心是基于距离），支持促销查询等场景，但都是高度依赖固定过滤条件的场景。\n那么，假如让我来完善召回逻辑的多样性，参考业界还有以下做法：\n实时场景召回：捕捉用户当下即时需求，适配实时搜索、场景突变等动态场景，如雨天优先召回热饮商家。 历史行为召回：满足用户 “复购” 或 “相似需求”，适用于老用户、有明确消费记录的场景。 时效性热门召回：满足 “从众” 需求（避免踩坑），新用户、无明确偏好用户、时段场景。 协同过滤召回：基于用户或商品相似度挖掘隐性关联，适合行为丰富但需求模糊的用户，如为买美式咖啡的人推荐全麦三明治。 以上，通过覆盖这些不同维度的需求，系统确保推荐结果丰富多样，避免用户总是看到千篇一律的内容，从而提升用户体验。\n各路召回策略的具体实现，可以参考下翻到第三章。\n2.2、效率性原则 # 2.3、可扩展性原则 # 外卖业务处于不断发展变化之中，新的商家持续入驻，用户需求也在不断演变，新的消费场景和流行趋势层出不穷。多路召回系统必须具备良好的可扩展性，以适应这些变化。这意味着系统架构能够方便地支持新增召回策略。比如，随着外卖平台开始涉足生鲜配送领域，为了满足用户对生鲜商品的需求，系统可以快速添加基于生鲜品类特点的召回策略，如优先召回提供新鲜直采、当日达生鲜服务的商家。同时，对于已有的召回策略，也能根据业务发展进行灵活调整与优化，确保系统始终能精准匹配不断变化的业务需求。\n2.4、数据驱动原则 # 用户行为数据、商家数据等海量数据是多路召回系统的 “燃料”。通过对用户行为数据的深入分析，系统能够洞察用户的真实需求与偏好。例如，通过分析用户在 APP 上的浏览轨迹、点击行为、下单记录等，系统可以精准勾勒出用户的兴趣画像，了解用户对不同菜系、价格区间、商家品牌的喜好程度。对于商家数据，包括商家的菜品信息、评分评价、配送范围、营业状态等，系统可以从中挖掘出商家的优势与特点。基于这些数据洞察，系统能够对召回策略进行持续优化。比如，如果发现某一区域内用户对某类新菜品的关注度和下单率持续上升，系统可以相应地调整召回策略，增加这类菜品相关商家的召回权重，从而实现更精准、高效的推荐。\n3、外卖首页推荐场景下的召回策略设计 # 基于用户历史行为的召回 近期浏览 / 下单商家召回：优先召回用户近期有过交互的商家\n品类偏好召回：根据用户历史下单品类，召回同品类优质商家\n价格带偏好召回：匹配用户常消费的价格区间商家\n基于实时场景的召回 地理位置召回：结合用户当前位置，优先召回距离近、配送快的商家\n时段召回：如早餐时段重点召回早餐类商家，午餐时段侧重快餐类商家\n天气场景召回：如雨天增加雨衣、热饮相关商品 / 商家的召回权重\n基于热门与优质内容的召回 平台热门商家召回：召回近期订单量高、评分好的热门商家\n新店 / 活动商家召回：针对新入驻或有优惠活动的商家进行召回，提升平台新鲜感\n优质口碑召回：根据用户评价、商家评分等维度筛选出的高口碑商家\n基于协同过滤的召回 相似用户偏好召回：参考与目标用户行为相似的用户的下单商家进行召回\n商家关联召回：如用户下单过某汉堡店，可召回搭配度高的饮品店\n4、多路召回系统的工程实现要点 # 数据层：用户行为数据、商家数据、商品数据的采集与存储 实时数据处理：采用流处理框架（如 Flink）处理用户实时行为\n离线数据处理：通过批处理任务（如 Spark）生成用户画像、商家特征等\n召回层：各召回策略的具体实现与调度 召回策略的并行计算：确保多策略同时运行，提升召回效率\n召回结果的初步过滤：去除无效商家（如已打烊、超出配送范围等）\n融合层：多源召回结果的整合与排序 权重分配：根据不同召回策略的效果（如点击率、转化率）动态调整权重\n去重处理：避免同一商家在推荐列表中重复出现\n服务层：系统的接口设计与性能优化 接口响应速度优化：通过缓存、索引等方式提升接口性能\n服务高可用：采用集群部署、熔断降级等策略保障系统稳定运行\n5、系统效果评估与迭代 # 评估指标：点击率（CTR）、下单转化率（CVR）、平均订单金额、用户留存率等\nA/B 测试：新召回策略上线前通过 A/B 测试验证效果\n迭代机制：根据评估结果与业务反馈，持续优化召回策略与系统参数\n6、外卖场景下的特殊挑战与解决方案 # 商家动态变化：如商家营业时间、库存、配送范围等变化 解决方案：实时同步商家状态数据，在召回环节进行动态过滤 用户需求突变：如用户临时想吃某类美食，与历史偏好差异较大 解决方案：结合用户实时搜索、浏览行为，增强实时场景召回的权重 冷启动问题：新用户、新商家的召回 新用户：基于用户注册信息（如地理位置、口味偏好选择）、热门内容进行召回\n新商家：通过新店扶持政策，在特定时段增加其召回权重\n7、未来展望 # 引入更智能的召回策略：如基于深度学习的召回模型\n提升系统的个性化程度：更精准地捕捉用户的细分需求\n结合业务生态拓展召回维度：如融入用户社交关系、跨平台行为等数据\n","externalUrl":null,"permalink":"/posts/1%E4%B8%9A%E5%8A%A1%E8%83%8C%E6%99%AF%E4%B8%8E%E5%8F%AC%E5%9B%9E%E7%B3%BB%E7%BB%9F%E4%BB%B7%E5%80%BC/","section":"Posts","summary":"\u003cp\u003e在加入LineMan之后，我负责的是多路召回这部分。多路召回是干啥的呢？简单来说，当我们打开类似美团的外卖app，在无关键字检索的情况下，首页需要展示推荐餐厅。那么，都展示哪些餐厅呢，凭什么把它们展示出来呢？这就涉及到多路召回的逻辑了。\u003c/p\u003e","title":"","type":"posts"},{"content":"","externalUrl":null,"permalink":"/ja/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/ja/","section":"Blowfish","summary":"","title":"Blowfish","type":"page"},{"content":"","externalUrl":null,"permalink":"/ja/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/ja/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","externalUrl":null,"permalink":"/ja/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"}]